{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d34f021",
   "metadata": {},
   "source": [
    "## Part 5: Testing our neural network on our own handwritten digits\n",
    "\n",
    "In this last tutorial, we'll load an image of a handwritten digit that I took and test our neural network on it. Being that my handwriting is not a part of MNIST's dataset, I don't expect the neural network to always know what my digits are. \n",
    "\n",
    "At the end of this tutorial, we'll provide graph paper for you to write your own digits on, then we'll test the neural network on a bunch of handwritten digits, instead of just a few. We'll see how well our NN will be able to interpret handwriting that isn't similar to its training set.\n",
    "\n",
    "Just like before, we'll load our NN and our training/testing set, as well as the path to the image of my handwritten 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19faa3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and some functions that are written for you \n",
    "from handwrite_functions import *\n",
    "model = torch.load('./my_mnist_model.pt')\n",
    "# where you put your image of a digit\n",
    "load_mydigit = \"../datasets/five_real.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af222bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where you want to save your dataset\n",
    "dataset = 'MY_DATASET'\n",
    "testset = 'MY_TESTSET'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# download training sets and test sets \n",
    "trainset = datasets.MNIST(dataset, download=False, train=True, transform=transform)\n",
    "valset = datasets.MNIST(testset, download=False, train=False, transform=transform)\n",
    "\n",
    "# load training sets and test sets in batch sizes of 64\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
    "\n",
    "# prepare loaded data sets to iterate over\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a205435",
   "metadata": {},
   "source": [
    "We'll load our custom image and take a look at the size/shape of the pixels. (What are pixels and what do the numbers mean?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ef2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your custom image of a digit\n",
    "custom_image_path = load_mydigit\n",
    "\n",
    "# Read in custom image\n",
    "custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))\n",
    "\n",
    "# Print out image data to check if reading worked.\n",
    "print(\"These are the shading (0 - 255) of each pixel\")\n",
    "print(f\"Custom image tensor:\\n{custom_image_uint8}\\n\")\n",
    "print(f\"Custom image shape: {custom_image_uint8.shape}\\n\")\n",
    "print(f\"Custom image dtype: {custom_image_uint8.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c735b0",
   "metadata": {},
   "source": [
    "Maybe our image has some noise and we want to apply a filter. You can try this step and load your de-noised image to test it in the next part. De-noising looks like applying a smoothing filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f1bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to \"de-noise\" your image? Try this after naming your \"output_image_path\"\n",
    "output_image_path = \"/Users/sierra/Downloads/five_denoise.png\"\n",
    "denoise_img(custom_image_path, output_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7afcd9",
   "metadata": {},
   "source": [
    "---\n",
    "Now, we'll normalize the pixels in the image to make this compatible with our neural network. We should only see 0s and 1s in the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931fc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in your custom image and convert the values to floats \n",
    "custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)\n",
    "\n",
    "# Divide each pixel value by 255 to get them between [0, 1]\n",
    "custom_image = custom_image / 255. \n",
    "\n",
    "# Invert the colors so that the digit is black on a light background\n",
    "custom_image = np.abs(custom_image - 1)\n",
    "\n",
    "# Rount each pixel to 1 or 0 for maximum contrast!\n",
    "custom_image = np.round(custom_image)\n",
    "# Print out image data - does it look like the other one?\n",
    "print(f\"Custom image tensor:\\n{custom_image}\\n\")\n",
    "print(f\"Custom image shape: {custom_image.shape}\\n\")\n",
    "print(f\"Custom image dtype: {custom_image.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da148c",
   "metadata": {},
   "source": [
    "If we try to test our neural network on this, it won't know what to do! The MNIST dataset contains images with 28x28 pixels. The image I took has 924x756 pixels, so the NN will not be able to operate on the mismatched sizes. \n",
    "\n",
    "Luckily, PyTorch has a function to resize our image into 28x28. Whew!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8392c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to make sure that the original image matches in shape, otherwise our NN will be confused\n",
    "custom_image_transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)), #MNIST only provides 28x28 so let's change ours to match\n",
    "])\n",
    "\n",
    "# Transform target image\n",
    "custom_image_transformed = custom_image_transform(custom_image)\n",
    "\n",
    "# Print out original shape and new shape\n",
    "print(f\"Original shape: {custom_image.shape}\")\n",
    "print(f\"New shape: {custom_image_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7477e37",
   "metadata": {},
   "source": [
    "It's finally time to test our image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our image!\n",
    "img = custom_image_transformed[0].view(1, 784)\n",
    "\n",
    "# plot our image as seen by torchvision\n",
    "plt.imshow(custom_image_transformed[0].numpy().squeeze(), cmap='gray_r')\n",
    "plt.axis(False);\n",
    "\n",
    "# use our NN to test on our image\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "ps = torch.exp(logps)\n",
    "probab = list(ps.numpy()[0])\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
    "print(f\"How sure?: {max(probab) * 100:.4} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89eab9b",
   "metadata": {},
   "source": [
    "Since my NN wasn't super confident (although it got the right answer!), I want to know what else the neural network thought it could be. Mine suggests that it could be a `3` or a `9`. Do you see how it could be mistaken?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b414b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun, let's look at what the NN \"thought\" of other options.\n",
    "for i in np.array(probab):\n",
    "    print(f\"{i * 100:.4}% digit could be {probab.index(i)}\")\n",
    "    \n",
    "# Are there any that come close? Do you see why the NN could \"think\" it would be another digit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305e45c",
   "metadata": {},
   "source": [
    "# Activity:\n",
    "1. We'll provide graph paper and have you fill in digits 0-9 a few times. You'll scan this and save it to a file. There's a script to split the image into test images with labels, so we'll try to test this neural network on that. Show us the steps to read in those images and save an image of the confusion matrix that results! (This is quite a few steps, so work with each other and ask for help if needed).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "Congratulations on finishing these tutorials! Next, we'll try to do the whole process again on neutrino interactions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
